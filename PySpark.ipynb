{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUFe1d4a9f4gOlh9SKVAg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neema233/Batch_Processing/blob/main/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QLc-1CqgsbVN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .appName('testColab') \\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "pKsj83o6tBbD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied \"\n",
        "\"from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "ui_port = 4040\n",
        "public_url = ngrok.connect(ui_port).public_url\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{ui_port}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZIY4gkXMtiEA",
        "outputId": "7dd73823-48f8-4f26-8678-3f5658fa0abd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-03-04T19:12:38+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://2624-34-74-83-222.ngrok-free.app\" -> \"http://127.0.0.1:4040\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing spark\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "file_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet'\n",
        "spark.sparkContext.addFile(file_url)\n",
        "\n",
        "df = spark.read.csv(SparkFiles.get('yellow_tripdata_2023-07.parquet'),\n",
        "      header=True)\n",
        "\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J3-JQOrDu5zw",
        "outputId": "ea6cbb19-dd6a-4c2f-f286-f83ecb65b971"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "377471"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2VL7Cxt0vMyR",
        "outputId": "253b64a1-f60d-4669-e1d8-87151410873a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-04 19:12:55--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T191255Z&X-Amz-Expires=300&X-Amz-Signature=1b010a4f39f8f4971e0c89332296d926f55bb6208b6bf9061cce367c3e8ded85&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-03-04 19:12:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T191255Z&X-Amz-Expires=300&X-Amz-Signature=1b010a4f39f8f4971e0c89332296d926f55bb6208b6bf9061cce367c3e8ded85&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19375751 (18M) [application/octet-stream]\n",
            "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
            "\n",
            "fhv_tripdata_2019-1 100%[===================>]  18.48M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-04 19:12:56 (127 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l fhv_tripdata_2019-10.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9Zn7MC6AwIPS",
        "outputId": "db5248d0-016c-45b3-dca0-951ec5379836"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62958 fhv_tripdata_2019-10.csv.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .csv('fhv_tripdata_2019-10.csv.gz')"
      ],
      "metadata": {
        "id": "tm7Ug5ctwb3c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h3EMDcFpxBqw",
        "outputId": "7ff48a95-abab-4264-b13b-a15d1c104029"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(dispatching_base_num='B00009', pickup_datetime='2019-10-01 00:23:00', dropOff_datetime='2019-10-01 00:35:00', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00009'),\n",
              " Row(dispatching_base_num='B00013', pickup_datetime='2019-10-01 00:11:29', dropOff_datetime='2019-10-01 00:13:22', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00013'),\n",
              " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:11:43', dropOff_datetime='2019-10-01 00:37:20', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014'),\n",
              " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:56:29', dropOff_datetime='2019-10-01 00:57:47', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014'),\n",
              " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:23:09', dropOff_datetime='2019-10-01 00:28:27', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jH_vVYRrxzAC",
        "outputId": "4eff445c-7437-4d3f-c66e-7795c29bc23f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2VE6sANCyrMg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas=pd.read_csv('/content/fhv_tripdata_2019-10.csv.gz')"
      ],
      "metadata": {
        "id": "suhq81zrywwL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aHdfecyIzN7y",
        "outputId": "9ba60f85-00be-4eaf-ce97-9cc7967bd80f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dispatching_base_num       object\n",
              "pickup_datetime            object\n",
              "dropOff_datetime           object\n",
              "PUlocationID              float64\n",
              "DOlocationID              float64\n",
              "SR_Flag                   float64\n",
              "Affiliated_base_number     object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(df_pandas).schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nIHPZvzkziCi",
        "outputId": "55a0084f-aaad-4156-8b62-6be7eef85e91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import types"
      ],
      "metadata": {
        "id": "zihr9fWs2vwv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema= types.StructType([\n",
        "types.StructField('dispatching_base_num', types.StringType(), True),\n",
        "types.StructField('pickup_datetime', types.TimestampType(), True),\n",
        "types.StructField('dropOff_datetime', types.TimestampType(), True),\n",
        "types.StructField('PUlocationID', types.IntegerType(), True),\n",
        "types.StructField('DOlocationID', types.IntegerType(), True),\n",
        "types.StructField('SR_Flag', types.StringType(), True),\n",
        "types.StructField('Affiliated_base_number', types.StringType(), True)])"
      ],
      "metadata": {
        "id": "20agbLcO25H0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(schema)\\\n",
        "    .csv('fhv_tripdata_2019-10.csv.gz')"
      ],
      "metadata": {
        "id": "xXGs1rhY3CRY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XnedooxZ3POe",
        "outputId": "6ad2440e-a66a-492d-9caa-c38a704f2e40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2019, 10, 1, 0, 23), dropOff_datetime=datetime.datetime(2019, 10, 1, 0, 35), PUlocationID=264, DOlocationID=264, SR_Flag=None, Affiliated_base_number='B00009')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.repartition(6)"
      ],
      "metadata": {
        "id": "Uxd48SZd3fzc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet(\"fhv_tripdata_2019-10_partitions\")"
      ],
      "metadata": {
        "id": "Qv4CURzU3q7I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh fhv_tripdata_2019-10_partitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cFD4MB4U5h6r",
        "outputId": "e8528cb3-7d9f-4ef0-be1f-8c4f60aa4b66"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 39M\n",
            "-rw-r--r-- 1 root root 6.4M Mar  4 19:15 part-00000-12f8f29a-cb04-4850-9df2-33dc6e5f11ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 6.4M Mar  4 19:15 part-00001-12f8f29a-cb04-4850-9df2-33dc6e5f11ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 6.4M Mar  4 19:15 part-00002-12f8f29a-cb04-4850-9df2-33dc6e5f11ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 6.4M Mar  4 19:15 part-00003-12f8f29a-cb04-4850-9df2-33dc6e5f11ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 6.4M Mar  4 19:15 part-00004-12f8f29a-cb04-4850-9df2-33dc6e5f11ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 6.4M Mar  4 19:15 part-00005-12f8f29a-cb04-4850-9df2-33dc6e5f11ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root    0 Mar  4 19:15 _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.parquet('fhv_tripdata_2019-10_partitions')"
      ],
      "metadata": {
        "id": "fx-GeVgF5t5q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHcx2sG16WQ2",
        "outputId": "a5c9a713-de20-405c-edea-97518aaef08a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
            "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
            "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
            "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   NULL|                  NULL|\n",
            "|              B02429|2019-10-21 04:15:47|2019-10-21 04:36:04|         264|         264|   NULL|                B02429|\n",
            "|              B01482|2019-10-19 12:00:00|2019-10-19 12:20:00|         264|         264|   NULL|                B01482|\n",
            "|              B03015|2019-10-11 14:28:00|2019-10-11 14:32:44|         264|         216|   NULL|                B03015|\n",
            "|              B01529|2019-10-21 18:00:26|2019-10-21 18:07:21|         264|          80|   NULL|                B01529|\n",
            "|              B00477|2019-10-03 19:30:35|2019-10-03 20:27:57|         161|          14|   NULL|                B00477|\n",
            "|              B00937|2019-10-25 06:10:40|2019-10-25 06:29:43|         264|         208|   NULL|                B00937|\n",
            "|     B00889         |2019-10-30 06:18:02|2019-10-30 06:35:12|         260|         260|   NULL|       B00889         |\n",
            "|              B01239|2019-10-09 03:39:16|2019-10-09 03:42:07|         264|         254|   NULL|                B00882|\n",
            "|              B00256|2019-10-27 11:54:37|2019-10-27 12:28:18|         264|         264|   NULL|                B00256|\n",
            "|              B01087|2019-10-14 18:41:24|2019-10-14 19:02:06|         261|         186|   NULL|                B01087|\n",
            "|              B02846|2019-10-19 11:42:45|2019-10-19 12:42:42|         264|          23|   NULL|                B02846|\n",
            "|              B02546|2019-10-17 15:20:32|2019-10-17 15:25:51|         264|         167|   NULL|                B02546|\n",
            "|              B02803|2019-10-21 05:00:47|2019-10-21 05:03:44|          47|         169|   NULL|                B02803|\n",
            "|              B01644|2019-10-14 11:34:00|2019-10-14 13:12:00|         264|         264|   NULL|                B01644|\n",
            "|              B01454|2019-10-13 07:08:41|2019-10-13 07:13:43|         264|         188|   NULL|                B01454|\n",
            "|              B01239|2019-10-24 06:05:22|2019-10-24 06:15:03|         264|         174|   NULL|                B00882|\n",
            "|              B01751|2019-10-20 09:49:18|2019-10-20 10:40:59|         264|         264|   NULL|                B01751|\n",
            "|              B00887|2019-10-06 17:17:28|2019-10-06 18:12:14|         264|         132|   NULL|                B00887|\n",
            "|              B01362|2019-10-07 11:25:57|2019-10-07 11:39:15|         264|         185|   NULL|                B01362|\n",
            "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the longest trip in day\n",
        "from pyspark.sql import functions as F\n",
        "longest_trip=df.withColumn(\"trip length\",(F.col(\"dropOff_datetime\").cast(\"long\") - F.col(\"pickup_datetime\").cast(\"long\"))/3600)\n",
        "longest_duration_hours =longest_trip.select(F.max(\"trip length\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUG29a0QA7Sw",
        "outputId": "5a33661e-1980-40fd-f303-21efa6458d17"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|max(trip length)|\n",
            "+----------------+\n",
            "|        631152.5|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "df \\\n",
        ".withColumn(\"pickup_datetime\",F.to_date(\"pickup_datetime\"))\\\n",
        ".withColumn(\"dropOff_datetime\",F.to_date(\"dropOff_datetime\"))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x7rX8M7958Tv",
        "outputId": "9a317d0e-78c0-4f27-e277-bc7e99fa824e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+----------------+------------+------------+-------+----------------------+\n",
            "|dispatching_base_num|pickup_datetime|dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
            "+--------------------+---------------+----------------+------------+------------+-------+----------------------+\n",
            "|              B02784|     2019-10-01|      2019-10-01|          89|          85|   NULL|                  NULL|\n",
            "|              B02429|     2019-10-21|      2019-10-21|         264|         264|   NULL|                B02429|\n",
            "|              B01482|     2019-10-19|      2019-10-19|         264|         264|   NULL|                B01482|\n",
            "|              B03015|     2019-10-11|      2019-10-11|         264|         216|   NULL|                B03015|\n",
            "|              B01529|     2019-10-21|      2019-10-21|         264|          80|   NULL|                B01529|\n",
            "|              B00477|     2019-10-03|      2019-10-03|         161|          14|   NULL|                B00477|\n",
            "|              B00937|     2019-10-25|      2019-10-25|         264|         208|   NULL|                B00937|\n",
            "|     B00889         |     2019-10-30|      2019-10-30|         260|         260|   NULL|       B00889         |\n",
            "|              B01239|     2019-10-09|      2019-10-09|         264|         254|   NULL|                B00882|\n",
            "|              B00256|     2019-10-27|      2019-10-27|         264|         264|   NULL|                B00256|\n",
            "|              B01087|     2019-10-14|      2019-10-14|         261|         186|   NULL|                B01087|\n",
            "|              B02846|     2019-10-19|      2019-10-19|         264|          23|   NULL|                B02846|\n",
            "|              B02546|     2019-10-17|      2019-10-17|         264|         167|   NULL|                B02546|\n",
            "|              B02803|     2019-10-21|      2019-10-21|          47|         169|   NULL|                B02803|\n",
            "|              B01644|     2019-10-14|      2019-10-14|         264|         264|   NULL|                B01644|\n",
            "|              B01454|     2019-10-13|      2019-10-13|         264|         188|   NULL|                B01454|\n",
            "|              B01239|     2019-10-24|      2019-10-24|         264|         174|   NULL|                B00882|\n",
            "|              B01751|     2019-10-20|      2019-10-20|         264|         264|   NULL|                B01751|\n",
            "|              B00887|     2019-10-06|      2019-10-06|         264|         132|   NULL|                B00887|\n",
            "|              B01362|     2019-10-07|      2019-10-07|         264|         185|   NULL|                B01362|\n",
            "+--------------------+---------------+----------------+------------+------------+-------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numbers of taxi in 15th\n",
        "filtered_data = df.filter(df.pickup_datetime.cast(\"date\") == \"2019-10-15\")\n",
        "print(filtered_data.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "C_kcbjgt6kqx",
        "outputId": "a0f89f6d-0760-4627-fdf0-863cc3d446a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "fhv_df = spark.read.csv(\"fhv_tripdata_2019-10.csv.gz\")\n",
        "fhv_df.createOrReplaceTempView(\"tripdatafhv\")\n",
        "zone_data = spark.read.csv(\"taxi_zone_lookup.csv\")\n",
        "zone_data.createOrReplaceTempView(\"zones\")\n",
        "\n",
        "\n",
        "joined_df = spark.sql(\"\"\"  SELECT z.zone, COUNT(f.PUlocationID) AS pickups\n",
        "  FROM tripdatafhv f\n",
        "  JOIN zones z ON f.PUlocationID = z.location_id\n",
        "  GROUP BY z.zone\"\"\")\n",
        "\n",
        "\n",
        "zone_counts = joined_df.groupBy(\"zone\").count()\n",
        "\n",
        "least_frequent_zone = zone_counts.sort(F.col(\"count\").asc()).first()[0]\n",
        "\n",
        "print(\"Least frequent pickup location zone:\", least_frequent_zone)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "m3BpAZye9mhS",
        "outputId": "228a44ea-b6e4-4b4f-8af5-6a451ae53a39"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `f`.`PUlocationID` cannot be resolved. Did you mean one of the following? [`f`.`_c0`, `z`.`_c0`, `f`.`_c1`, `z`.`_c1`, `f`.`_c2`].; line 3 pos 18;\n'Aggregate ['z.zone], ['z.zone, 'COUNT('f.PUlocationID) AS pickups#1613]\n+- 'Join Inner, ('f.PUlocationID = 'z.location_id)\n   :- SubqueryAlias f\n   :  +- SubqueryAlias tripdatafhv\n   :     +- View (`tripdatafhv`, [_c0#1574,_c1#1575,_c2#1576,_c3#1577,_c4#1578,_c5#1579,_c6#1580])\n   :        +- Relation [_c0#1574,_c1#1575,_c2#1576,_c3#1577,_c4#1578,_c5#1579,_c6#1580] csv\n   +- SubqueryAlias z\n      +- SubqueryAlias zones\n         +- View (`zones`, [_c0#1605,_c1#1606,_c2#1607,_c3#1608])\n            +- Relation [_c0#1605,_c1#1606,_c2#1607,_c3#1608] csv\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-d8bf8af6635d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m joined_df = spark.sql(\"\"\"  SELECT z.zone, COUNT(f.PUlocationID) AS pickups\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mFROM\u001b[0m \u001b[0mtripdatafhv\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mJOIN\u001b[0m \u001b[0mzones\u001b[0m \u001b[0mz\u001b[0m \u001b[0mON\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUlocationID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `f`.`PUlocationID` cannot be resolved. Did you mean one of the following? [`f`.`_c0`, `z`.`_c0`, `f`.`_c1`, `z`.`_c1`, `f`.`_c2`].; line 3 pos 18;\n'Aggregate ['z.zone], ['z.zone, 'COUNT('f.PUlocationID) AS pickups#1613]\n+- 'Join Inner, ('f.PUlocationID = 'z.location_id)\n   :- SubqueryAlias f\n   :  +- SubqueryAlias tripdatafhv\n   :     +- View (`tripdatafhv`, [_c0#1574,_c1#1575,_c2#1576,_c3#1577,_c4#1578,_c5#1579,_c6#1580])\n   :        +- Relation [_c0#1574,_c1#1575,_c2#1576,_c3#1577,_c4#1578,_c5#1579,_c6#1580] csv\n   +- SubqueryAlias z\n      +- SubqueryAlias zones\n         +- View (`zones`, [_c0#1605,_c1#1606,_c2#1607,_c3#1608])\n            +- Relation [_c0#1605,_c1#1606,_c2#1607,_c3#1608] csv\n"
          ]
        }
      ]
    }
  ]
}